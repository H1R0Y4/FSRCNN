{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from numpy import random\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from collections import OrderedDict\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "uses_device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "print(uses_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperResolutionNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SuperResolutionNN, self).__init__()\n",
    "        self.layer = nn.Sequential(OrderedDict([\n",
    "            (\"conv1\",nn.Conv2d(1,56,kernel_size=5,stride=1,padding=0)),\n",
    "            (\"PR1\",nn.PReLU()),\n",
    "            (\"conv2\",nn.Conv2d(56,12,1,1,0)),\n",
    "            (\"PR2\",nn.PReLU()),\n",
    "            (\"conv3\",nn.Conv2d(12,12,3,1,1)),\n",
    "            (\"PR3\",nn.PReLU()),\n",
    "            (\"conv4\",nn.Conv2d(12,12,3,1,1)),\n",
    "            (\"PR4\",nn.PReLU()),\n",
    "            (\"conv5\",nn.Conv2d(12,12,3,1,1)),\n",
    "            (\"PR5\",nn.PReLU()),\n",
    "            (\"conv6\",nn.Conv2d(12,12,3,1,1)),\n",
    "            (\"PR6\",nn.PReLU()),\n",
    "            (\"conv7\",nn.Conv2d(12,56,1,1,1)),\n",
    "            (\"PR7\",nn.PReLU()),\n",
    "            (\"Deconv\",nn.ConvTranspose2d(56,1,9,3,4))\n",
    "        ]))\n",
    "        nn.init.normal_(self.layer.conv1.weight, 0.0, 0.0378)\n",
    "        nn.init.normal_(self.layer.conv2.weight, 0.0, 0.3536)\n",
    "        nn.init.normal_(self.layer.conv3.weight, 0.0, 0.1179)\n",
    "        nn.init.normal_(self.layer.conv4.weight, 0.0, 0.189)\n",
    "        nn.init.normal_(self.layer.conv4.weight, 0.0, 0.0001)\n",
    "    \n",
    "    def forward(self,x,t=None, train=True):\n",
    "        # :param x: 入力値\n",
    "        # :param t: 正解のラベル\n",
    "        # :param train: 学習かどうか\n",
    "        out = self.layer(z)\n",
    "        #損失か結果を返す\n",
    "        #差の絶対値の平均(平均二乗誤差)\n",
    "        return nn.MSELoss(out,t) if train else out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self,path2label,transform=None):\n",
    "        self.transform = transform\n",
    "        self.path = path2label\n",
    "    def __len__(self):\n",
    "        return len(self.path)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        img = np.array(Image.open(list(self.path.keys())[idx]))/255.0\n",
    "        img = cv2.resize(img,(300,300))\n",
    "        label = list(self.path.values())[idx]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SuperResolutionNN().to(uses_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19314\n"
     ]
    }
   ],
   "source": [
    "img_path = glob.glob('../../DATASETS/anime-face-dataset/data/*')\n",
    "print(len(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(img_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #データセットの呼び出し\n",
    "# path_label=[]\n",
    "# fp = os.listdir('/home/b20saito/DATASETS/anime-face-dataset/data/')\n",
    "# #print(fp)\n",
    "# for fn in fp:\n",
    "#     img = Image.open('/home/b20saito/DATASETS/anime-face-dataset/data/' + fn).resize((320, 320)).convert('YCbCr')\n",
    "#     path_label.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(path_label,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.6.9",
   "language": "python",
   "name": "3.6.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
