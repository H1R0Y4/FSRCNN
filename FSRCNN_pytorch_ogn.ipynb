{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考サイト\n",
    "- [FSRCNN_withPytorch](https://github.com/yjn870/FSRCNN-pytorch)\n",
    "\n",
    "- [個人的にわかりやすいpytorchチュートリアル](https://qiita.com/mckeeeen/items/e255b4ac1efba88d0ca1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collections import OrderedDict\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FSRCNN(nn.Module):\n",
    "    def __init__(self, scale_factor):\n",
    "        super(FSRCNN, self).__init__()\n",
    "        self.first_layer = nn.Sequential(OrderedDict([\n",
    "            (\"fl_conv\",nn.Conv2d(1,56,kernel_size=5,padding = 2)),\n",
    "            (\"fl_PReLU\",nn.PReLU(56))\n",
    "        ]))\n",
    "        \n",
    "        self.middle_layer =nn.Sequential(OrderedDict([\n",
    "            (\"ml_conv1\",nn.Conv2d(56,12,kernel_size=1)),\n",
    "            (\"ml_PReLU1\",nn.PReLU(12)),\n",
    "            \n",
    "            (\"ml_conv2\",nn.Conv2d(12,12,kernel_size=3,padding=1)),\n",
    "            (\"ml_PReLU2\",nn.PReLU(12)),\n",
    "            \n",
    "            (\"ml_conv3\",nn.Conv2d(12,12,kernel_size=3,padding=1)),\n",
    "            (\"ml_PReLU3\",nn.PReLU(12)),\n",
    "            \n",
    "            (\"ml_conv4\",nn.Conv2d(12,12,kernel_size=3,padding=1)),\n",
    "            (\"ml_PReLU4\",nn.PReLU(12)),\n",
    "            \n",
    "            (\"ml_conv5\",nn.Conv2d(12,12,kernel_size=3,padding=1)),\n",
    "            (\"ml_PReLU5\",nn.PReLU(12)),\n",
    "            \n",
    "            (\"ml_conv6\",nn.Conv2d(12,56,kernel_size=1)),\n",
    "            (\"ml_PReLU6\",nn.PReLU(56)),\n",
    "        ]))\n",
    "        \n",
    "        self.last_layer = nn.Sequential(OrderedDict([\n",
    "            (\"ll_Deconv\",nn.ConvTranspose2d(56,1,\n",
    "                                            kernel_size=9,stride=scale_factor,padding=4,output_padding=scale_factor-1))\n",
    "        ]))\n",
    "#         self._initialize_weights()\n",
    "\n",
    "#     def _initialize_weights(self):\n",
    "#         for m in self.first_part:\n",
    "#             if isinstance(m, nn.Conv2d):\n",
    "#                 nn.init.normal_(m.weight.data, mean=0.0, std=math.sqrt(2/(m.out_channels*m.weight.data[0][0].numel())))\n",
    "#                 nn.init.zeros_(m.bias.data)\n",
    "#         for m in self.mid_part:\n",
    "#             if isinstance(m, nn.Conv2d):\n",
    "#                 nn.init.normal_(m.weight.data, mean=0.0, std=math.sqrt(2/(m.out_channels*m.weight.data[0][0].numel())))\n",
    "#                 nn.init.zeros_(m.bias.data)\n",
    "#         nn.init.normal_(self.last_part.weight.data, mean=0.0, std=0.001)\n",
    "#         nn.init.zeros_(self.last_part.bias.data)\n",
    "        nn.init.normal_(self.first_layer.fl_conv.weight, 0.0, 0.0378)\n",
    "        nn.init.zeros_(self.first_layer.fl_conv.bias.data)\n",
    "        nn.init.normal_(self.middle_layer.ml_conv1.weight, 0.0, 0.3536)\n",
    "        nn.init.zeros_(self.middle_layer.ml_conv1.bias.data)\n",
    "        nn.init.normal_(self.middle_layer.ml_conv2.weight, 0.0, 0.1179)\n",
    "        nn.init.zeros_(self.middle_layer.ml_conv2.bias.data)\n",
    "        nn.init.normal_(self.middle_layer.ml_conv3.weight, 0.0, 0.1179)\n",
    "        nn.init.zeros_(self.middle_layer.ml_conv3.bias.data)\n",
    "        nn.init.normal_(self.middle_layer.ml_conv4.weight, 0.0, 0.1179)\n",
    "        nn.init.zeros_(self.middle_layer.ml_conv4.bias.data)\n",
    "        nn.init.normal_(self.middle_layer.ml_conv5.weight, 0.0, 0.1179)\n",
    "        nn.init.zeros_(self.middle_layer.ml_conv5.bias.data)\n",
    "        nn.init.normal_(self.middle_layer.ml_conv6.weight, 0.0, 0.189)\n",
    "        nn.init.zeros_(self.middle_layer.ml_conv6.bias.data)\n",
    "        nn.init.normal_(self.last_layer.ll_Deconv.weight, 0.0, 0.001)\n",
    "        nn.init.zeros_(self.last_layer.ll_Deconv.bias.data)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.first_layer(x)\n",
    "        x = self.middle_layer(x)\n",
    "        x = self.last_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データセットの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, h5_file):\n",
    "        super(TrainDataset, self).__init__()\n",
    "        self.h5_file = h5_file\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        with h5py.File(self.h5_file, 'r') as f:\n",
    "            return np.expand_dims(f['lr'][idx] / 255.,0), \\\n",
    "                   np.expand_dims(f['hr'][idx] /255.,0)\n",
    "    \n",
    "    def __len__(self):\n",
    "        with h5py.File(self.h5_file, 'r') as f:\n",
    "            return len(f['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalDataset(Dataset):\n",
    "    def __init__(self, h5_file):\n",
    "        super(EvalDataset, self).__init__()\n",
    "        self.h5_file= h5_file\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        with h5py.File(self.h5_file, 'r') as f:\n",
    "            return np.expand_dims(f['lr'][str(idx)][:,:]/255.,0), np.expand_dims(f['hr'][str(idx)][:,:]/255.,0)\n",
    "    \n",
    "    def __len__(self):\n",
    "        with h5py.File(self.h5_file, 'r') as f:\n",
    "            return len(f['lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [np.expand_dims()とは](https://teratail.com/questions/146318)\n",
    "- np.expand_dims() は、第2引数の axis で指定した場所の直前に dim=1 を挿入します。負の値の場合は、Python の添字記法と同じ末尾からの参照になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100, 3)\n",
      "(1, 100, 100, 3)\n",
      "255.0\n"
     ]
    }
   ],
   "source": [
    "img = np.zeros((100, 100, 3), dtype=float)\n",
    "print(img.shape)  # (100, 100, 3)\n",
    "_img = np.expand_dims(img,axis=0)#0番目の軸の前にdim=1を挿入\n",
    "print(_img.shape)\n",
    "print(255.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSNR計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_psnr(img1,img2):\n",
    "    return 10. * torch.log10(1. / torch.mean((img1-img2) ** 2)) #10.はfloat型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "    \n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count +=n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. arg系で指定されていたものの書き換え\n",
    "\n",
    "[num_workerとは](https://stackoverflow.com/questions/53998282/how-does-the-number-of-workers-parameter-in-pytorch-dataloader-actually-work)\n",
    "- num_workers = 2の場合、最大2人のワーカーが同時にデータをRAMに入れます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"test_dir/h5_of_anime-face-datasets_Train3.h5\"#訓練所のファイル\n",
    "eval_file = \"test_dir/h5_of_anime-face-datasets_eval3.h5\" #eval=評価するためのファイル\n",
    "outputs_dir = \"output\" #出力ファイル\n",
    "weights_file = \"\" #重みファイル\n",
    "scale = 2 #画像の拡大率　default=2\n",
    "lr = 1e-3  #学習率 1e-3\n",
    "batch_size=16 #バッチサイズ 16\n",
    "num_epochs=20 #エポック数\n",
    "num_workers= 8 #num_workersでいくつのコアでデータをロードするか指定(デフォルトはメインのみ)\n",
    "seed = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 出力先ディレクトリの作成と指定\n",
    "- 後で実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output/x2_4\n"
     ]
    }
   ],
   "source": [
    "scale_output_dir = os.path.join(outputs_dir,'x{}_4'.format(scale))\n",
    "print(scale_output_dir)\n",
    "if not os.path.exists(scale_output_dir):\n",
    "    os.makedirs(scale_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. cuDNNのベンチマークモードをオンにするかどうかのオプション\n",
    "- Trueにするとオートチューナーがネットワークの構成に対し最適なアルゴリズムを見つけるため、高速化されます.\n",
    "- [benchmark=Trueとは](https://qiita.com/koshian2/items/9877ed4fb3716eac0c37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 使うデバイスを指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. [シード値の初期化](https://qrunch.net/@haru256/entries/HW8uMhxBnEJ1qnFr)\n",
    "- torchでのRNGを初期化\n",
    "- RNG(Random Number Generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f807e6ff4b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 作成したモデル(NN)のインスタンスを生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FSRCNN(scale_factor=scale).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 損失関数(平均二乗誤差)のインスタンスを生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.Adamのインスタンスを生成\n",
    "- 要素が辞書型のlist型のデータでパラメータを設定している\n",
    "- Variableの代わりに辞書型で返すことができる\n",
    "- 詳しくはこのサイト→　https://pytorch.org/docs/stable/optim.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam([\n",
    "    {'params': model.first_layer.parameters()},\n",
    "    {'params': model.middle_layer.parameters()},\n",
    "    {'params': model.last_layer.parameters(), 'lr': lr *0.1}\n",
    "], lr = lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. [データのロード](https://qiita.com/takurooo/items/e4c91c5d78059f92e76d)\n",
    "- [pin_memory=Trueとは](https://discuss.pytorch.org/t/when-to-set-pin-memory-to-true/19723)→　CPUのデータセットにサンプルをロードし、GPUへのトレーニング中にサンプルをプッシュしたい場合、pin_memoryを有効にすることでホストからデバイスへの転送を高速化できます。\n",
    "\n",
    "- [deepcopy](https://kurochan-note.hatenablog.jp/entry/20110316/1300267023) → オブジェクトとメモリ上のデータ(インスタンス変数)の両方をコピーする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrainDataset(train_file)\n",
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=num_workers,\n",
    "                              pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = EvalDataset(eval_file)\n",
    "eval_dataloader = DataLoader(dataset=eval_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights = copy.deepcopy(model.state_dict()) #モデルを辞書型でbest_weightsにコピーする\n",
    "best_epoch = 0\n",
    "best_psnr = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習\n",
    "\n",
    "- [no_grad](https://qiita.com/a_yoshii/items/598365cf3b68955e11c5)\n",
    " - pytorchではtrain時，forward計算時に勾配計算用のパラメータを保存しておくことでbackward計算の高速化を行っている\n",
    " - model.eval()で行っていてもパラメータが保存されているようなので，下記対策が必要\n",
    " - torch.no_grad()を使用してパラメータの保存を止める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 0/19: : 142104it [00:44, 3173.34it/s, loss=0.005850]                     \n",
      "epoch: 1/19:   0%|                                   | 0/142096 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 22.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 1/19: : 142104it [00:44, 3173.47it/s, loss=0.005534]                     \n",
      "epoch: 2/19:   0%|                                   | 0/142096 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 22.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 2/19: : 142104it [00:44, 3171.88it/s, loss=0.005385]                     \n",
      "epoch: 3/19:   0%|                                   | 0/142096 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 22.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 3/19: : 142104it [00:44, 3178.43it/s, loss=0.005321]                     \n",
      "epoch: 4/19:   0%|                                   | 0/142096 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 22.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 4/19: : 142104it [00:44, 3169.42it/s, loss=0.005260]                     \n",
      "epoch: 5/19:   0%|                                   | 0/142096 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 22.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 5/19: : 142104it [00:44, 3173.43it/s, loss=0.005214]                     \n",
      "epoch: 6/19:   0%|                                   | 0/142096 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 22.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 6/19: : 142104it [00:44, 3166.02it/s, loss=0.005179]                     \n",
      "epoch: 7/19:   0%|                                   | 0/142096 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 22.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 7/19: : 142104it [00:45, 3147.73it/s, loss=0.005136]                     \n",
      "epoch: 8/19:   0%|                                   | 0/142096 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 22.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 8/19: : 142104it [00:45, 3152.46it/s, loss=0.005102]                     \n",
      "epoch: 9/19:   0%|                                   | 0/142096 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 22.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 9/19: : 142104it [00:44, 3172.33it/s, loss=0.005079]                     \n",
      "epoch: 10/19:   0%|                                  | 0/142096 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 23.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 10/19: : 142104it [00:44, 3176.21it/s, loss=0.005059]                    \n",
      "epoch: 11/19:   0%|                                  | 0/142096 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 23.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 11/19: : 142104it [00:45, 3136.11it/s, loss=0.005042]                    \n",
      "epoch: 12/19:   0%|                                  | 0/142096 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 23.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 12/19: : 142104it [00:45, 3143.95it/s, loss=0.005029]                    \n",
      "epoch: 13/19:   0%|                                  | 0/142096 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 23.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 13/19: : 142104it [00:44, 3167.68it/s, loss=0.005013]                    \n",
      "epoch: 14/19:   0%|                                  | 0/142096 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 23.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 14/19: : 142104it [00:44, 3171.61it/s, loss=0.005002]                    \n",
      "epoch: 15/19:   0%|                                  | 0/142096 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 22.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 15/19: : 142104it [00:44, 3168.71it/s, loss=0.004991]                    \n",
      "epoch: 16/19:   0%|                                  | 0/142096 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 23.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 16/19: : 142104it [00:44, 3169.67it/s, loss=0.004983]                    \n",
      "epoch: 17/19:   0%|                                  | 0/142096 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 23.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 17/19: : 142104it [00:44, 3164.71it/s, loss=0.004976]                    \n",
      "epoch: 18/19:   0%|                                  | 0/142096 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 23.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 18/19: : 142104it [00:44, 3174.29it/s, loss=0.004969]                    \n",
      "epoch: 19/19:   0%|                                  | 0/142096 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 23.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 19/19: : 142104it [00:44, 3171.25it/s, loss=0.004962]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 22.87\n",
      "best epoch: 12, psnr: 23.18\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    #訓練==================================================================================\n",
    "    model.train() #訓練モードにする\n",
    "    epoch_losses = AverageMeter() #AverageMeter()のインスタンスを作成する\n",
    "    with tqdm(total=(len(train_dataset) - len(train_dataset) % batch_size), ncols=80) as t: #len(train_dataset) - len(train_dataset) % batch_size)が最大値のプログレスバーを作成する ncols=80はプログレスバーの長さ\n",
    "        t.set_description('epoch: {}/{}'.format(epoch, num_epochs - 1)) #epoch:1/２0 |######     | のような説明文をつける\n",
    "        \n",
    "        for data in train_dataloader:\n",
    "            inputs, labels = data #低解像度をinputs、高解像度を正解labelに代入\n",
    "\n",
    "            inputs = inputs.to(device) #inputsをGPUに載せる\n",
    "            labels = labels.to(device) #labelsをGPUに載せる\n",
    "\n",
    "            preds = model(inputs) #GPUにのせたinputsをmodelに予測させる(xを返す)\n",
    "\n",
    "            loss = criterion(preds, labels) #予測データと、正解データを平均二乗誤差で損失を計算する\n",
    "            \n",
    "            epoch_losses.update(loss.item(), len(inputs)) #アベレージメーターを更新する\n",
    "\n",
    "            optimizer.zero_grad() #勾配の初期化\n",
    "            loss.backward() #勾配の計算\n",
    "            optimizer.step() #重みの更新\n",
    "            \n",
    "            t.set_postfix(loss='{:.6f}'.format(epoch_losses.avg)) #プログレスバーの横に表示させる変数の順番を設定する\n",
    "            t.update(len(inputs)) #進捗バーを自分のタイミングで進める\n",
    "        \n",
    "    torch.save(model.state_dict(), os.path.join(scale_output_dir, 'epoch_{}.pth'.format(epoch)))\n",
    "    \n",
    "    \n",
    "    #評価==================================================================================\n",
    "    model.eval()#評価モードにする\n",
    "    epoch_psnr = AverageMeter() #AverageMeter()のインスタンスを作成する\n",
    "    for data in eval_dataloader:\n",
    "        inputs, labels = data #低解像度をinputs、高解像度をlabelに代入\n",
    "        \n",
    "        inputs = inputs.to(device) #inputsをGPUに載せる\n",
    "        labels = labels.to(device) #labelsをGPUに載せる\n",
    "        \n",
    "        with torch.no_grad(): #パラメータの保存を止める 評価モードはパラメータを保存する必要はない\n",
    "            preds = model(inputs).clamp(0.0,1.0) #パラメータの保存を止めつつ、予測させる.clamp(min,max)\n",
    "        \n",
    "        epoch_psnr.update(calc_psnr(preds, labels), len(inputs)) # アベレージメータを更新する\n",
    "    \n",
    "    print('eval psnr: {:.2f}'.format(epoch_psnr.avg)) #評価モードのpsnr値を表示する\n",
    "    \n",
    "    if epoch_psnr.avg > best_psnr:\n",
    "        best_epoch = epoch\n",
    "        best_psnr = epoch_psnr.avg\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "print('best epoch: {}, psnr: {:.2f}'.format(best_epoch, best_psnr)) #psnr値がよかったepochとそのpsnr値を表示する\n",
    "torch.save(best_weights, os.path.join(scale_output_dir,'best.pth')) #最適な重みをbest.pth\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.6.9",
   "language": "python",
   "name": "3.6.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
