{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考サイト\n",
    "- [FSRCNN_withPytorch](https://github.com/yjn870/FSRCNN-pytorch)\n",
    "\n",
    "- [個人的にわかりやすいpytorchチュートリアル](https://qiita.com/mckeeeen/items/e255b4ac1efba88d0ca1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from collections import OrderedDict\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FSRCNN(nn.Module):\n",
    "    def __init__(self,scale_factor):\n",
    "        super(FSRCNN, self).__init__()\n",
    "        self.first_layer = nn.Sequential(OrderedDict([\n",
    "            (\"fl_conv\",nn.Conv2d(1,56,kernel_size=5,stride=1,padding=0)),\n",
    "            (\"fl_PReLU\",nn.PReLU())\n",
    "        ]))\n",
    "        \n",
    "        self.middle_layer =nn.Sequential(OrderedDict([\n",
    "            (\"ml_conv1\",nn.Conv2d(56,12,1,1,0)),\n",
    "            (\"ml_PReLU1\",nn.PReLU(56)),\n",
    "            \n",
    "            (\"ml_conv2\",nn.Conv2d(12,12,3,1,1)),\n",
    "            (\"ml_PReLU2\",nn.PReLU(12)),\n",
    "            \n",
    "            (\"ml_conv3\",nn.Conv2d(12,12,3,1,1)),\n",
    "            (\"ml_PReLU3\",nn.PReLU(12)),\n",
    "            \n",
    "            (\"ml_conv4\",nn.Conv2d(12,12,3,1,1)),\n",
    "            (\"ml_PReLU4\",nn.PReLU(12)),\n",
    "            \n",
    "            (\"ml_conv5\",nn.Conv2d(12,12,3,1,1)),\n",
    "            (\"ml_PReLU5\",nn.PReLU(12)),\n",
    "            \n",
    "            (\"ml_conv6\",nn.Conv2d(12,56,1,1,1)),\n",
    "            (\"ml_PReLU6\",nn.PReLU(56)),\n",
    "        ]))\n",
    "        \n",
    "        self.last_layer = nn.Sequential(OrderedDict([\n",
    "            (\"ll_Deconv\",nn.ConvTranspose2d(56,1,\n",
    "                                            kernel_size=9,stride=scale_factor,padding=4))\n",
    "        ]))\n",
    "        \n",
    "        nn.init.normal_(self.first_layer.fl_conv.weight, 0.0, 0.0378)\n",
    "        nn.init.zeros_(self.first_layer.fl_conv.bias.data)\n",
    "        nn.init.normal_(self.middle_layer.ml_conv1.weight, 0.0, 0.3536)\n",
    "        nn.init.zeros_(self.middle_layer.ml_conv1.bias.data)\n",
    "        nn.init.normal_(self.middle_layer.ml_conv2.weight, 0.0, 0.1179)\n",
    "        nn.init.zeros_(self.middle_layer.ml_conv2.bias.data)\n",
    "        nn.init.normal_(self.middle_layer.ml_conv3.weight, 0.0, 0.1179)\n",
    "        nn.init.zeros_(self.middle_layer.ml_conv3.bias.data)\n",
    "        nn.init.normal_(self.middle_layer.ml_conv4.weight, 0.0, 0.1179)\n",
    "        nn.init.zeros_(self.middle_layer.ml_conv4.bias.data)\n",
    "        nn.init.normal_(self.middle_layer.ml_conv5.weight, 0.0, 0.1179)\n",
    "        nn.init.zeros_(self.middle_layer.ml_conv5.bias.data)\n",
    "        nn.init.normal_(self.middle_layer.ml_conv6.weight, 0.0, 0.189)\n",
    "        nn.init.zeros_(self.middle_layer.ml_conv6.bias.data)\n",
    "        nn.init.normal_(self.last_layer.ll_Deconv.weight, 0.0, 0.0001)\n",
    "        nn.init.zeros_(self.last_layer.ll_Deconv.bias.data)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.first_layer(x)\n",
    "        x = self.middle_layer(x)\n",
    "        x = self.last_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データセットの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, h5_file):\n",
    "        super(TrainDataset, self).__init__()\n",
    "        self.h5_file = h5_file\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        with h5py.File(self.h5_file, 'r') as f:\n",
    "            return np.expand_dims(f['lr'][idx] / 255.,0), \\\n",
    "                   np.expand_dims(f['hr'][idx] /255.,0)\n",
    "    \n",
    "    def __len__(self):\n",
    "        with h5py.File(self.h5_file, 'r') as f:\n",
    "            return len(f['lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [np.expand_dims()とは](https://teratail.com/questions/146318)\n",
    "- np.expand_dims() は、第2引数の axis で指定した場所の直前に dim=1 を挿入します。負の値の場合は、Python の添字記法と同じ末尾からの参照になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100, 3)\n",
      "(1, 100, 100, 3)\n",
      "255.0\n"
     ]
    }
   ],
   "source": [
    "img = np.zeros((100, 100, 3), dtype=float)\n",
    "print(img.shape)  # (100, 100, 3)\n",
    "_img = np.expand_dims(img,axis=0)#0番目の軸の前にdim=1を挿入\n",
    "print(_img.shape)\n",
    "print(255.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. arg系で指定されていたものの書き換え\n",
    "\n",
    "[num_workerとは](https://stackoverflow.com/questions/53998282/how-does-the-number-of-workers-parameter-in-pytorch-dataloader-actually-work)\n",
    "- num_workers = 2の場合、最大2人のワーカーが同時にデータをRAMに入れます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"\"#訓練所のファイル\n",
    "eval_file = \"\" #eval=評価するためのファイル\n",
    "outputs_dir = \"output\" #出力ファイル\n",
    "weights_file = \"\" #重みファイル\n",
    "scale = 2 #画像の拡大率　default=2\n",
    "lr = 1e-3  #学習率 1e-3\n",
    "batch_size=16 #バッチサイズ 16\n",
    "num_epochs=20 #エポック数\n",
    "num_workers= 8 #num_workersでいくつのコアでデータをロードするか指定(デフォルトはメインのみ)\n",
    "seed = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 出力先ディレクトリの作成と指定\n",
    "- 後で実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_output_dir = os.path.join(outputs_dir,'x{}'.format(scale))\n",
    "print(scale_output_dir)\n",
    "#if not os.path.join(scale_output_dir):\n",
    "#    os.makedirs(scale_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. cuDNNのベンチマークモードをオンにするかどうかのオプション\n",
    "- Trueにするとオートチューナーがネットワークの構成に対し最適なアルゴリズムを見つけるため、高速化されます.\n",
    "- [benchmark=Trueとは](https://qiita.com/koshian2/items/9877ed4fb3716eac0c37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 使うデバイスを指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. [シード値の初期化](https://qrunch.net/@haru256/entries/HW8uMhxBnEJ1qnFr)\n",
    "- torchでのRNGを初期化\n",
    "- RNG(Random Number Generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fcbff112450>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 作成したモデル(NN)のインスタンスを生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FSRCNN(scale_factor=scale).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 損失関数(平均二乗誤差)のインスタンスを生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.Adamのインスタンスを生成\n",
    "- 要素が辞書型のlist型のデータでパラメータを設定している\n",
    "- Variableの代わりに辞書型で返すことができる\n",
    "- 詳しくはこのサイト→　https://pytorch.org/docs/stable/optim.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam([\n",
    "    {'params': model.first_layer.parameters()},\n",
    "    {'params': model.middle_layer.parameters()},\n",
    "    {'params': model.last_layer.parameters(), 'lr': lr *0.1}\n",
    "], lr = lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. [データのロード](https://qiita.com/takurooo/items/e4c91c5d78059f92e76d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrainDataset(train_file)\n",
    "train_dataloader = DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.6.9",
   "language": "python",
   "name": "3.6.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
