{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from numpy import random\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from collections import OrderedDict\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_path = glob.glob('/home/b20saito/CODE/BENKYO/chainer/chapter03/train/*')\n",
    "#print(len(img_path))\n",
    "images = []\n",
    "\n",
    "# 全てのファイル\n",
    "fs = glob.glob('/home/b20saito/CODE/BENKYO/chainer/chapter03/train/*')\n",
    "#fs = glob.glob('/home/b20saito/DATASETS/anime-face-dataset/data/*')\n",
    "for fn in fs:\n",
    "\t# 画像を読み込み\n",
    "\timg = Image.open(fn).resize((320, 320)).convert('YCbCr')\n",
    "\tcur_x = 0\n",
    "\twhile cur_x <= 320 - 40:\n",
    "\t\tcur_y = 0\n",
    "\t\twhile cur_y <= 320 - 40:\n",
    "\t\t\t# 画像から切りだし\n",
    "\t\t\trect = (cur_x, cur_y, cur_x+40, cur_y+40)\n",
    "\t\t\tcropimg = img.crop(rect).copy()\n",
    "\t\t\t# 配列に追加\n",
    "\t\t\timages.append(cropimg)\n",
    "\t\t\t# 次の切りだし場所へ\n",
    "\t\t\tcur_y += 20\n",
    "\t\tcur_x += 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "uses_device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "print(uses_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperResolutionNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SuperResolutionNN, self).__init__()\n",
    "        self.layer = nn.Sequential(OrderedDict([\n",
    "            (\"conv1\",nn.Conv2d(1,56,kernel_size=5,stride=1,padding=0)),\n",
    "            (\"PR1\",nn.PReLU()),\n",
    "            (\"conv2\",nn.Conv2d(56,12,1,1,0)),\n",
    "            (\"PR2\",nn.PReLU()),\n",
    "            (\"conv3\",nn.Conv2d(12,12,3,1,1)),\n",
    "            (\"PR3\",nn.PReLU()),\n",
    "            (\"conv4\",nn.Conv2d(12,12,3,1,1)),\n",
    "            (\"PR4\",nn.PReLU()),\n",
    "            (\"conv5\",nn.Conv2d(12,12,3,1,1)),\n",
    "            (\"PR5\",nn.PReLU()),\n",
    "            (\"conv6\",nn.Conv2d(12,12,3,1,1)),\n",
    "            (\"PR6\",nn.PReLU()),\n",
    "            (\"conv7\",nn.Conv2d(12,56,1,1,1)),\n",
    "            (\"PR7\",nn.PReLU()),\n",
    "            (\"Deconv\",nn.ConvTranspose2d(56,1,9,3,4))\n",
    "        ]))\n",
    "        nn.init.normal_(self.layer.conv1.weight, 0.0, 0.0378)\n",
    "        nn.init.normal_(self.layer.conv2.weight, 0.0, 0.3536)\n",
    "        nn.init.normal_(self.layer.conv3.weight, 0.0, 0.1179)\n",
    "        nn.init.normal_(self.layer.conv4.weight, 0.0, 0.189)\n",
    "        nn.init.normal_(self.layer.conv4.weight, 0.0, 0.0001)\n",
    "    \n",
    "    def forward(self,x,t=None, train=True):\n",
    "        # :param x: 入力値\n",
    "        # :param t: 正解のラベル\n",
    "        # :param train: 学習かどうか\n",
    "        out = self.layer(x)\n",
    "        #損失か結果を返す\n",
    "        #差の絶対値の平均(平均二乗誤差)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self,path,transform=None):\n",
    "        self.transform = transform\n",
    "        self.path = path\n",
    "    def __len__(self):\n",
    "        return len(self.path)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        img = Image.open(self.path[idx]).convert('YCbCr')\n",
    "        \n",
    "        #高解像度データ\n",
    "        hpix = np.array(img).astype(np.float32) /255.0\n",
    "        hp = hpix[:,:,0]\n",
    "        #print('==HR==\\n',hp.shape)\n",
    "        #低解像度データ\n",
    "        low = img.resize((16,16),Image.NEAREST)\n",
    "        lpix = np.array(low).astype(np.float32) / 255.0\n",
    "        lp = lpix[:,:,0]\n",
    "        #print('==LR==\\n',lp.shape)\n",
    "        return np.expand_dims(hp,0),np.expand_dims(lp,0),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データセットの作成と、呼び出し\n",
    "transform = transforms.Compose([transforms.ToTensor])\n",
    "dataset = MyDataset(img_path, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True) #batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ニューラルネットワークを作成\n",
    "model = SuperResolutionNN().to(uses_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#誤差逆電波法アルゴリズムを選択する\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dataloader:\n",
    "    model(data[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 320, 320])\n",
      "torch.Size([128, 1, 16, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 952, 952])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data[0].shape)\n",
    "print(data[1].shape)\n",
    "model.to(\"cpu\")(data[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossfc = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10000):\n",
    "    for lp,hp in dataloader:\n",
    "        output = model(input)\n",
    "        \n",
    "        loss = lossfc(output,target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "img = img_path[0]\n",
    "print(img)\n",
    "img = Image.open(img)\n",
    "img = np.asarray(img)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.6.9",
   "language": "python",
   "name": "3.6.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
